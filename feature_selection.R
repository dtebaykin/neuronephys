# Rank features (metadata) in the order of their predictive power of ephys. properties
# Rules of thumb: multivariate linear regression: 10-20 obs per parameter, RF: 3 obs per variable

# This R file requires datasets generated by Ephys_vs_conc.R file to be loaded, specifically data_models and the quality of life vectors from the top of the file
library(ggplot2)
library(devtools)
library(ggbiplot)
library(glmnetUtils)
library(mlbench)
library(reshape2)
library(randomForest)
library(party)
library(RColorBrewer)
library(pheatmap)
library(Metrics)
library(NeuralNetTools)
library(neuralnet)
library(formula.tools)
library(caret)
library(ggthemes)
library(splines)
library(data.table)

# parallel computation
#library(foreach)
#library(doMC)
#registerDoMC(cores = 2)

setwd("~/Documents/Neuroelectro documents")

ggplot(subset(data_models_rmp, NeuronName = "Hippocampus CA1 pyramidal cell"), aes(x = PubYear, y = rmp)) + geom_point() +
  labs(x = "Year published", y = "Resting membrane potential, mV") +
  stat_smooth(method = "lm") +
  theme_bw(15)

# Features to use, removed PrepType since its filtered to 'in vitro', "ElectrodeType" = Patch-Clamp
features = c('NeuronName','Species','Strain', 'ElectrodeType', 'PrepType',
             'RecTemp','AnimalAge','PubYear', 
             'external_0_Mg','external_0_Ca','external_0_Na','external_0_Cl','external_0_K',
             'internal_0_Mg','internal_0_Ca','internal_0_Na','internal_0_Cl','internal_0_K',
             "external_0_Cs", "internal_0_Cs", "external_0_glucose", "internal_0_glucose", "external_0_HEPES", "internal_0_HEPES", "external_0_EDTA", "internal_0_EDTA",
             "external_0_EGTA", "internal_0_EGTA", "external_0_BAPTA", "internal_0_BAPTA", "external_0_ATP", "internal_0_ATP", "external_0_GTP", "internal_0_GTP")

#ephys_interest <- c('rin','rmp','apthr','apamp','aphw','tau','ahpamp')
ephys_interest <- c("rin", "rmp","apthr","apamp", "aphw", "tau", "ahpamp", "rheo","maxfreq", "cap", "adratio")# , "sagratio", "sagamp")

# Specifically, using data_models dataset

# Fix RMP based on JxnPotential and JxnOffset
data_models$rmp = as.numeric(apply(data_models, 1 , function(x) {
  if (x['JxnPotential'] == "Corrected") {
    if (is.na(x['JxnOffset'])) {
      as.numeric(x['rmp']) + median(data_models[,'JxnOffset'], na.rm = TRUE)
    } else {
      as.numeric(x['rmp']) + abs(as.numeric(x['JxnOffset']))
    }  
  } else {
    x['rmp']
  }
}))

# Fix AP threshold based on JxnPotential and JxnOffset
data_models$apthr = as.numeric(apply(data_models, 1 , function(x) {
  if (x['JxnPotential'] == "Corrected") {
    if (is.na(x['JxnOffset'])) {
      as.numeric(x['apthr']) + median(data_models[,'JxnOffset'], na.rm = TRUE)
    } else {
      as.numeric(x['apthr']) + abs(as.numeric(x['JxnOffset']))
    }  
  } else {
    x['apthr']
  }
}))

data_models_x <- as.data.frame(unclass(data_models[,c(features, "Pmid")]))
# data_models_x <- as.data.frame(lapply(data_models_x, function(x) {
#   if (class(x) == "factor") {
#     as.numeric(x)
#   } else {
#     x
#   }
# }))

data_models_x[is.na(data_models_x$AnimalAge), "AnimalAge"] <- median(data_models_x$AnimalAge, na.rm = TRUE)
data_models_x[is.na(data_models_x$RecTemp), "RecTemp"] <- median(data_models_x$RecTemp, na.rm = TRUE)

fit_data <- cbind(data_models_x, data_models[,ephys_interest])

# data_models_x <- as.data.frame(sapply(colnames(data_models_x), function(x) {
#   vec = data_models_x[,x]
#   if (x %in% solns) {
#     vec[is.na(vec)] = 0.000001
#   } else if (class(data_models_x[,x]) == "numeric") {
#     m <- median(vec, na.rm = TRUE)
#     vec[is.na(vec)] <- m
#   }
#   return(vec)
# }))

### PCA analysis
data_models_x_pca <- prcomp(data_models_x_for_pca, center = T, scale. = T, tol = 0)

### Plot the data points on PC1-PC2 space
g <- ggbiplot(data_models_x_pca, obs.scale = 1, var.scale = 1)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
print(g)

### Add weights to the data using SD
weighted_data_models <- data_models
# for (ep in log10_ephys) {
#   weighted_data_models[, paste0(ep,  "_sd")] = log10(weighted_data_models[, paste0(ep,  "_sd")])
# }
for (ep in ephys_interest) {
  minsd = min(weighted_data_models[, paste0(ep, "_sd")], na.rm = T)
  weighted_data_models[, paste0(ep, "_freq")] <- round(100 * minsd / weighted_data_models[, paste0(ep, "_sd")] + 1)
}
weighted_fit_data <- cbind(data_models_x, weighted_data_models[, c(ephys_interest, paste0(ephys_interest, "_freq"))])

### Feature selection, 100 runs with 90% train : 10% test data split. Next time paralellize it: mclapply or foreach
get_R2 <- function(obs, pred) {
  1 - sum((obs - pred)^2) / sum((obs - mean(obs))^2 )
}

# Create a dataset with randomized ephys properties
rand_data <- as.data.frame(apply(fit_data[, ephys_interest], 2, function(x) {
  sample(x)
}))
rand_data <- cbind(fit_data[,features], rand_data)

### Function defining feature selection process: use standard RF and unbiased / regress out correlations approach
nrun = 10
rf_result <- data.frame(matrix(0, ncol = length(features)*nrun, nrow = length(c(ephys_interest, features))))
colnames(rf_result) <- 1:(length(features)*nrun)
rownames(rf_result) <- c(ephys_interest, features)
runnum = 1

for (n in 1:nrun) {
combn(features, 17, FUN = function (i) {

#run_model <- function () {

for (ep in ephys_interest) {
  frml = as.formula(paste(ep, " ~ ",
                          # Combinatorial formula
                          paste(i, collapse = "+")
                          
                          # all meta
                          #paste(features, collapse = "+")
                          
                          # No neuron types
                          #paste(setdiff(colnames(data_models_x), c("NeuronName")), collapse = "+")
                          
                          # No solutions
                          #paste(c('NeuronName','Species','Strain','JxnPotential','JxnOffset','RecTemp','AnimalAge','PubYear'), collapse = "+")
                          
                          # Just Neuron Types
                          #"NeuronName"
                          
                          # Just solutions
                          #paste(solns, collapse = "+")
  ))
  
  run_data = fit_data[!is.na(fit_data[,ep]),]
  run_data = run_data[complete.cases(run_data[,c(ep, features)]),]
  run_data = run_data[sample(nrow(run_data)),]
  
  # Force unique pmid's into splits
  run_data$fold = 0
  pmids <- unique(run_data$Pmid)
  for (k in 1:10) {
    split <- pmids[seq(k, length(pmids), 10)]
    run_data[run_data$Pmid %in% split,]$fold = k
  }
  
  temp_rf_res = c()
  #temp_fs_res = c()
# 10x cross-validation
  for (k in 1:10) {
    print(paste0("Run : ", runnum, ", EP: ", ep, ", Fold #", k))
    
    rf = randomForest(frml, run_data[run_data$fold != k, c(colnames(data_models_x), ep)], importance = F )
    rf_pred = predict(rf, newdata = run_data[run_data$fold == k, c(colnames(data_models_x), ep)], type = "response")
    temp_rf_res = c(temp_rf_res, get_R2(run_data[run_data$fold == k, ep], rf_pred))
    
    
    #rf_vals[paste0(ep, "_real_", k)] <<- c(run_data[run_data$fold == k, ep], rep(NaN, 100 - length(rf_pred)))
    #rf_vals[paste0(ep, "_pred_", k)] <<- c(rf_pred, rep(NaN, 100 - length(rf_pred)))
    
    # Grab mean decrease accuracy measure <- biased towards continuous vars / vars with a lot of different values
    #rf_list <<- rbind(rf_list, c(importance(rf, type = 1)))
    
    # Try an unbiased RF feature selection
    # Problems of all above: preference of correlated predictor variables: Nicodemus and Shugart, 2007; Archer and Kimes, 2008
    #fs = cforest(frml, run_data[run_data$fold != k, c(colnames(data_models_x), ep)], controls = cforest_control(teststat = "max",
  #                                                                      testtype = "Teststatistic",
  #                                                                      mincriterion = x,
  #                                                                      savesplitstats = FALSE,
  #                                                                      ntree = y, mtry = z, replace = T,
  #                                                                      trace = T))
  
    #fs_pred = predict(fs, newdata = run_data[run_data$fold == k, c(colnames(data_models_x), ep)], type = "response", OOB = F)
    # Solution: conditional importance mostly removes effects of correlations between predictor vars. Strobl et al. (2008)
    # fs_imp = varimp(fs, conditional = T)
    
    #temp_fs_res = c(temp_fs_res, get_R2(run_data[run_data$fold == k, ep], fs_pred))
    # fs_list <<- rbind(fs_list, fs_imp)
  } # end of 10x cross validation
    rf_result[ep, runnum] <<- mean(temp_rf_res)
   # fs_result <<- cbind(fs_result, temp_fs_res)
  } 
    rf_result[rownames(rf_result) %in% i, runnum] <<- 1
    
    runnum <<- runnum + 1
    #mean(apply(fs_result, 2, mean) - apply(rf_result, 2, mean))
  } # end of function
, simplify = F)}

# TODO: feature importance, include glmnet model for each RF model
# TODO: model for ions of interest vs all soln concs
# TODO: try to adjust NeuroElectro data to Jim's data's metadata, compare the distributions

compare_models <- function () {
  for (ep in ephys_interest) {
    frmls = list(as.formula(paste(ep, " ~ NeuronName")))
    frmls[[2]] = as.formula(paste(ep, " ~ ", paste(setdiff(features, solns), collapse = "+")))
    frmls[[3]] = as.formula(paste(ep, " ~ ", paste(solns, collapse = "+")))
    frmls[[4]] = as.formula(paste(ep, " ~ NeuronName + ", paste(solns, collapse = "+")))
    frmls[[5]] = as.formula(paste(ep, " ~ ", paste(setdiff(features, c(solns, "NeuronName")), collapse = "+")))
    frmls[[6]] = as.formula(paste(ep, " ~ ", paste(features, collapse = "+")))
    
    frmls[[7]] = as.formula(paste(ep, " ~ NeuronName"))
    frmls[[8]] = as.formula(paste(ep, " ~ NeuronName + Species + bs(RecTemp, df = 5) + bs(log10(AnimalAge), df = 5) + bs(PubYear, df = 5)"))
    frmls[[9]] = as.formula(paste(ep, " ~ ", paste(solns, collapse = "+")))
    frmls[[10]] = as.formula(paste(ep, " ~ NeuronName + ", paste(solns, collapse = "+")))
    frmls[[11]] = as.formula(paste(ep, " ~ Species + bs(RecTemp, df = 5) + bs(log10(AnimalAge), df = 5) + bs(PubYear, df = 5)"))
    frmls[[12]] = as.formula(paste(ep, " ~ NeuronName + Species + bs(RecTemp, df = 5) + bs(log10(AnimalAge), df = 5) + bs(PubYear, df = 5) + ", paste(solns, collapse = "+")))
    
    frmls[[13]] = as.formula(paste(ep, " ~ ", paste(solns[grepl("Na|Mg|Ca|K|Cl", solns)], collapse = "+")))
    frmls[[14]] = as.formula(paste(ep, " ~ NeuronName + ", paste(solns[grepl("Na|Mg|Ca|K|Cl", solns)], collapse = "+")))
    frmls[[15]] = as.formula(paste(ep, " ~ ", paste(setdiff(features, solns[!grepl("Na|Mg|Ca|K|Cl", solns)]), collapse = "+")))
    
    #run_data = weighted_fit_data[!is.na(weighted_fit_data[,ep]),]
    #run_data = run_data[complete.cases(run_data[,c(ep, features, paste0(ep, "_freq"))]),]
    #run_data = run_data[rep(row.names(run_data), run_data[,paste0(ep, "_freq")]),]
    
    run_data = fit_data[!is.na(fit_data[,ep]),]
    run_data = run_data[which(
      run_data[,ep] > quantile(run_data[,ep], 0.01) &
      run_data[,ep] < quantile(run_data[,ep], 0.99)
    ),]
    
    run_data = run_data[sample(nrow(run_data)),]
    
    # Force unique pmid's into splits
    run_data$fold = 0
    pmids <- unique(run_data$Pmid)
    for (i in 1:10) {
      split <- pmids[seq(i, length(pmids), 10)]
      run_data[run_data$Pmid %in% split,]$fold = i
    }
    
    # Randomly assign folds
    #run_data$fold = rep(1:10, length.out = nrow(run_data))
    
    temp_rf_res = c()
    temp_rf_mse = c()    
    #splits <- c()
    
    #temp_lasso_res = c()
    #temp_ridge_res = c()
    #temp_knn_res = c()
    
    # 10x cross-validation
    for (i in 1:length(frmls)) {
      #frml = lapply(features, function(x) { grepl(x, as.character(frmls[[i]])) })
      for (k in 1:10) {
        print(paste0("Run: ", runnum, ", EP: ", ep, ", Model #", i, ", Fold #", k))
        
        # Get split information
        #temp <- setdiff(run_data[run_data$fold == k, "Pmid"], run_data[run_data$fold != k, "Pmid"])
        #splits <- c(splits, nrow(subset(run_data, fold == k & Pmid %in% temp)) / nrow(subset(run_data, fold == k)) )
        if (grepl("NeuronName", frmls[[i]]) & (i < 7 | i > 12 )) {
          rf_formula = gsub("NeuronName", "1", frmls[[i]])
          rf_data = run_data
          rf_data$NeuronName = droplevels(rf_data$NeuronName)
          
          for(level in unique(rf_data$NeuronName)){
            rf_data[paste("NeuronName", make.names(level), sep = "_")] <- ifelse(rf_data$NeuronName == level, 1, 0)
            rf_formula = paste(rf_formula, paste("NeuronName", make.names(level), sep = "_"), sep = "+")
          }
          rf_data$NeuronName = NULL
          rf_formula = gsub("1\\+", "", rf_formula)
        } else {
          rf_formula = frmls[[i]]
          rf_data = run_data
        }
        
        if ( i > 6 & i < 13) {
          rf_fit = cv.glmnet(as.formula(rf_formula), data = rf_data[rf_data$fold != k,], nlambda = 100, alpha=.99, na.action = na.omit)
          rf_pred = as.vector(predict(rf_fit, newdata = rf_data[rf_data$fold == k,], s = "lambda.min"))
        } else {
          rf_fit = randomForest(as.formula(rf_formula), data = rf_data[rf_data$fold != k,], importance = T)
          rf_pred = predict(rf_fit, newdata = rf_data[rf_data$fold == k,], type = "response")
          rf_importance = c(rf_importance, importance(rf_fit, type = 2))
        }
        temp_rf_res = c(temp_rf_res, get_R2(run_data[run_data$fold == k, ep], rf_pred))
        temp_rf_mse = c(temp_rf_mse, mse(run_data[run_data$fold == k, ep], rf_pred))
        
        #lasso_fit = cv.glmnet(formula = frmls[[i]], data = run_data[run_data$fold != k, c(features[unlist(frml)], ep)], alpha = 1)
        #lasso_pred = predict(lasso_fit, newdata = run_data[run_data$fold == k, features], type = "response")
        #temp_lasso_res = c(temp_lasso_res, get_R2(run_data[run_data$fold == k, ep], lasso_pred))

        #ridge_fit = cv.glmnet(frmls[[i]], data = run_data[run_data$fold != k, c(features[unlist(frml)], ep)], alpha = 0)
        #ridge_pred = predict(ridge_fit, newdata = run_data[run_data$fold == k, features], type = "response")
        #temp_ridge_res = c(temp_ridge_res, get_R2(run_data[run_data$fold == k, ep], ridge_pred))
        
        #knn_data_train = model.matrix(frmls[[i]], run_data[run_data$fold != k, ])
        #knn_data_test = model.matrix(frmls[[i]], run_data[run_data$fold == k, ])
        #knn_fit = knnreg(frmls[[i]], knn_data_train, k = 15, use.all = F)
        #knn_pred = predict(knn_fit, knn_data_test)
        #temp_knn_res = c(temp_knn_res, get_R2(run_data[run_data$fold == k, ep], knn_pred))
       
        rf_vals[[i]][paste0(ep, "_real_", k)] <<- c(run_data[run_data$fold == k, ep], rep(NaN, 2000 - length(rf_pred)))
        rf_vals[[i]][paste0(ep, "_pred_", k)] <<- c(rf_pred, rep(NaN, 2000 - length(rf_pred)))
        
        #rf_result[[i]][paste0(ep, "_r2"), runnum] <<- get_R2(run_data[run_data$fold == k, ep], rf_pred)
        #rf_result[[i]][paste0(ep, "_mse"), runnum] <<- mean(temp_rf_mse)
        #lasso_result[[i]][paste0(ep, "_r2"), runnum] <<- get_R2(run_data[run_data$fold == k, ep], lasso_pred)
        #ridge_result[[i]][paste0(ep, "_r2"), runnum] <<- get_R2(run_data[run_data$fold == k, ep], ridge_pred)
        #knn_result[[i]][paste0(ep, "_r2"), runnum] <<- get_R2(run_data[run_data$fold == k, ep], knn_pred)
        
        #runnum <<- runnum + 1
      } # end of 10x cross validation
      rf_result[[i]][paste0(ep, "_r2"), runnum] <<- mean(temp_rf_res)
      rf_result[[i]][paste0(ep, "_mse"), runnum] <<- mean(temp_rf_mse)
#       lasso_result[[i]][paste0(ep, "_r2"), runnum] <<- mean(temp_lasso_res)
#       ridge_result[[i]][paste0(ep, "_r2"), runnum] <<- mean(temp_ridge_res)
#       nn_result[[i]][paste0(ep, "_r2"), runnum] <<- mean(temp_nn_res)
    } 
    
    #rf_splits[, runnum] <<- splits
  } 
  
  runnum <<- runnum + 1
}

### Find optimal parameters for cforest
#for (x in c(0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8)) {
#for (y in c(50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 500)) {
#for (z in 5:20) {

# optimal parameters for cforest: (replace = T) <- R^2 goes down by 0.1 if we do not sample with replacement
  x = 0.05
  y = 110
  z = 10
  

### Run start for run_model()
nrun = 100
rf_result <- data.frame(matrix(0, ncol = nrun, nrow = 7))
colnames(rf_result) <- 1:nrun
rownames(rf_result) <- ephys_interest
runnum = 1
rf_splits <- data.frame(matrix(0, ncol = nrun, nrow = 10))

# Get actual / predicted values
rf_vals = data.frame(matrix(NaN, ncol = length(ephys_interest)*2*nrun, nrow = nrun))
rf_vals_names = c()
for (k in 1: nrun) {
   rf_vals_names = c(rf_vals_names, c(paste0(ephys_interest, "_real_", k), paste0(ephys_interest, "_pred_", k)))
}
colnames(rf_vals) = rf_vals_names

for (i in 1: nrun) { 
  run_model()
}
  #rf_result <- data.frame(matrix(0, ncol = 0, nrow = 10))
  #fs_result <- data.frame(matrix(0, ncol = 0, nrow = 10))
#}
#}
#}
#}



### Run start for compare_models()
nrun = 10
rf_result = list()
rf_importance = list()

#lasso_result = list()
#ridge_result = list()
#knn_result = list()

rf_vals = list()
rf_vals_names = c()
for (k in 1:nrun) {
  rf_vals_names = c(rf_vals_names, c(paste0(ephys_interest, "_real_", k), paste0(ephys_interest, "_pred_", k)))
}

for (i in 1:15) {
  rf_temp = data.frame(matrix(0, ncol = nrun, nrow = length(ephys_interest) * 2))
  colnames(rf_temp) <- 1:nrun
  rownames(rf_temp) <- c(paste0(ephys_interest, "_r2"), paste0(ephys_interest, "_mse"))
  rf_result[[i]] <- rf_temp
  
  #lasso_result[[i]] = rf_temp
  #ridge_result[[i]] = rf_temp
  #knn_result[[i]] = rf_temp

  rf_temp = data.frame(matrix(NaN, ncol = length(ephys_interest)*2*nrun, nrow = 2000))
  colnames(rf_temp) = rf_vals_names
  rf_vals[[i]] <- rf_temp
}
rm(rf_temp, rf_vals_names)

# # Get actual / predicted values
runnum = 1
for (i in 1: nrun) {
  compare_models()
}
### Run end compare_models()



plot_run_data(as.data.frame(t(rf_result[[1]][1:length(ephys_interest),])), "RandomForest, all features")

# Plot real vs predicted vals
plot_rf_vals(rf_vals[[6]], rf_result[[6]][1:length(ephys_interest),])

# Plot means of each model
plot_data <- as.data.frame(apply(as.data.frame(t(rf_result[[1]])), 2, mean))
for (i in 2:6) {
  plot_data <- cbind(plot_data, (apply(as.data.frame(t(rf_result[[i]])), 2, mean)))
}

colnames(plot_data) <- c("NN only", "No solns", "Solns", "NN + Solns", "No NN + No solns", "All")
plot_data <- as.data.frame(t(plot_data))
plot_data$model = rownames(plot_data)
temp <- apply(fit_data[, ephys_interest], 2, function(x) {
  abs(mean(x, na.rm = TRUE))
})
plot_data[,grep("mse", colnames(plot_data))] <- sweep(plot_data[,grep("mse", colnames(plot_data))], 2, temp, '/')
rm(temp)
plot_data <- melt(plot_data, id = "model")

cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(plot_data[grepl("r2", plot_data$variable),], aes(x = variable, y = value)) + 
  geom_boxplot(aes(fill = model), position = "dodge", stat = "identity") +
  #geom_point() +
  scale_fill_manual(values=cbbPalette) +
  ggtitle("R^2, forced unique Pmids") +
  theme_bw(20)

# Plot means for glmnet vs RandomForest
models <- c("Neuron Type", "NT + basic metadata", "Solutions", "NT + solutions", "Basic metadata", "All features", "NT, glmnet", "NT + basic metadata, glmnet", "Solutions, glmnet", "NT + solutions, glmnet", "Basic metadata, glmnet", "All features, glmnet")
tempo = rf_result[1:12]
  #rf_12_models_result
for (i in seq_along(tempo)) {
  model = models[i]
  if (i == 1) {
    plot_data <- as.data.frame(t(tempo[[i]]))
    plot_data <- cbind(plot_data, model)
  } else {
    temp = as.data.frame(t(tempo[[i]]))
    temp = cbind(temp, model)
    plot_data <- rbind(plot_data, temp)
  }
}
rm(temp, model, models, tempo)

plot_data <- plot_data[order(plot_data[,"model"]),]
temp <- apply(fit_data[, ephys_interest], 2, function(x) {
  abs(sd(x, na.rm = TRUE))
})
plot_data[,grep("mse", colnames(plot_data))] <- sweep(plot_data[,grep("mse", colnames(plot_data))], 2, temp, '/')
rm(temp)

plot_data <- melt(plot_data, id = "model")
plot_data <- plot_data[grepl("r2", plot_data$variable),]
plot_data$variable = droplevels(plot_data$variable)
levels(plot_data$variable) <- ephys_interest
#cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#F4A460")
cbbPalette <- c("#000000", "#000000", "#E69F00", "#E69F00", "#56B4E9", "#56B4E9", "#009E73", "#009E73", "#F0E442", "#F0E442", "#D55E00", "#D55E00")

plot_data$model = factor(plot_data$model, c("Neuron Type", "NT, glmnet", "NT + basic metadata", "NT + basic metadata, glmnet", "Solutions", "Solutions, glmnet", "NT + solutions", "NT + solutions, glmnet", "Basic metadata", "Basic metadata, glmnet", "All features", "All features, glmnet"))

# Remove big glmnet outliers
require(dplyr)
temp = plot_data %>% group_by(model, variable) %>% top_n(7, value)

p = ggplot(temp) + 
  geom_boxplot(aes(x = model, y = value, fill = model), position = "dodge") +
  labs(x = "", y = "") +
  scale_fill_manual(values=cbbPalette) +
  #ggtitle("R2, weighted forced unique Pmids, 10 runs") +
  theme_few(20) +
  facet_wrap(~variable, scales = "free_y")
  #theme(legend.position="none")
p
ggsave(plot=p,height=6,width=6,dpi=200, filename= paste0(getwd(), "/Plots/ModelComparisonGLMR2.pdf"), useDingbats=FALSE)
rm(temp)



# R2 vs N
plot_data$n <- apply(plot_data, 1, function(x) {
  length(which(!is.na(data_models[,x[2]])))
})
colnames(plot_data) <- c("model", "EphysProp", "value", "n")
ggplot(plot_data) + stat_smooth(method = "lm") + geom_point(aes(x = n, y = value, color = EphysProp), size = 2) + theme_bw(20)


# Solution histograms
plot_data <- data_models[, solns]
colnames(plot_data) <-  gsub("_0_", " ", colnames(plot_data))
plot_data <- melt(plot_data)
ggplot(plot_data, aes(x = value)) + geom_histogram() + facet_wrap(~variable, scales = "free_x") + theme_bw(10)





p = ggplot(plot_data, aes(x = model, y = rin_r2)) +
  geom_point(aes(colour = model), size = 3) +
  labs(x = "", y = "") +
  #scale_colour_manual(values=cbbPalette) +
  theme_few(20) +
  theme(legend.position="none")
print(p)
ggsave(plot=p,height=6,width=6,dpi=200, filename= paste0(getwd(), "/Plots/Rin.pdf"), useDingbats=FALSE)

# Plot rf real vs predicted values for each ephys property
plot_rf_vals <- function(vals, rf_res) {
  plot_data <- as.data.frame(vals[, 1:(length(ephys_interest)*2)])
  colnames(plot_data) <- gsub("_\\d*$", "", colnames(plot_data))
  for (i in 2:nrun - 1) {
    startI = length(ephys_interest)*2*i + 1
    endI = length(ephys_interest)*2*(i + 1)
    toBind <- vals[, startI : endI]
    colnames(toBind) <- colnames(plot_data)
    plot_data <- rbind(plot_data, toBind)
  }
  
#   toAttach <- data.frame(matrix(0, ncol = 1, nrow = nrun*2000))
#   for (i in 0:9) {
#     toAttach[(i*2000 + 1): ((i+1)*2000),] <- splits[i + 1]
#   }
  #colnames(toAttach) = "splits"
  #plot_data <- cbind(plot_data, toAttach)
  #plot_data$splits <- as.factor(plot_data$splits)
  #levels(plot_data$splits) <- c(0.1, 0.14, 0.16, 0.16, 0.18, 0.18)
  #droplevels(plot_data$splits)
  
  # log10(Input Resistance), MΩ. R^2 = 0.28
  g1 = ggplot(plot_data, aes(y = rin_pred, x = rin_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + labs(x = "Measured values: log10(Rin), MΩ", y = "Predicted values: log10(Rin), MΩ") + xlim(1.5, 3) + ylim(1.5, 3) + ggtitle("") + theme_few(15)
  plot(g1)
  g2 = ggplot(plot_data, aes(y = rmp_pred, x = rmp_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(-90, -40) + ylim(-90, -40) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$rmp), digits = 2, nsmall = 2))) + theme_bw(15)
  g3 = ggplot(plot_data, aes(y = apthr_pred, x = apthr_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(-60, -20) + ylim(-60, -20) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$apthr), digits = 2, nsmall = 2))) + theme_bw(15)
  g4 = ggplot(plot_data, aes(y = apamp_pred, x = apamp_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(50, 100) + ylim(50, 100) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$apamp), digits = 2, nsmall = 2))) + theme_bw(15)
  g5 = ggplot(plot_data, aes(y = aphw_pred, x = aphw_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(-0.5, 0.5) + ylim(-0.5, 0.5) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$aphw), digits = 2, nsmall = 2))) + theme_bw(15)
  g6 = ggplot(plot_data, aes(y = tau_pred, x = tau_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(0, 2) + ylim(0, 2) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$tau), digits = 2, nsmall = 2))) + theme_bw(15)
  g7 = ggplot(plot_data, aes(y = ahpamp_pred, x = ahpamp_real)) + geom_point() + geom_abline(aes(slope = 1, intercept = 0)) + xlim(0, 30) + ylim(0, 30) + ggtitle(paste0("R^2: ", format(mean(as.data.frame(t(rf_res))$ahpamp), digits = 2, nsmall = 2))) + theme_bw(15)
  
  print(multiplot(g1, g2, g3, g4, g5, g6, g7, cols = 3))
}

ggsave(plot=g1,height=6,width=6,dpi=200, filename= paste0(getwd(), "/Plots/Real vs predicted.pdf"), useDingbats=FALSE)

# plot run data
plot_run_data <- function(dat, title) {
  colnames(dat) <- 1:ncol(dat)
  plot_data <- melt(dat)
  plot_data$variable <- as.character(plot_data$variable)
  plot_data$variable <- as.numeric(plot_data$variable)
  #plot_data$variable <- plot_data$variable %% 7
  plot_data$variable <- as.factor(plot_data$variable)
  levels(plot_data$variable) <- ephys_interest
  
  print(ggplot(plot_data, aes(x = variable, y = value)) +
    #geom_violin(aes(fill = variable)) +
      stat_summary(fun.y="mean", geom="bar") +
      geom_point() +
    ggtitle(title) +
    labs(x = "Ephys props", y = "R^2 value") +
    #ylim(c(0,1)) +
    theme_bw(20)
  )
}

plot_run_data(as.data.frame(t(rf_result[1:9,])), "RandomForest, all features")
#plot_run_data(fs_result, "CForest optimized run")

# Plot relative impact of each metadata on ephys.
plot_heatmap_r2 <- function(dat) {
  dat = dat[1:7,]
  
  plot_data = data.frame(matrix(nrow = length(ephys_interest), ncol = length(features)))
  for (i in 1:length(features)) {
    plot_data[, i] = apply(dat[ ,seq(i, length(dat), length(features))], 1, mean)
  }
  
  plot_data = data.frame(rf_result_18feat - plot_data)
  colnames(plot_data) <- paste0("-", rev(features))
  #colnames(plot_data) <- features
  rownames(plot_data) <- ephys_interest
  
  pheatmap(plot_data, show_colnames = T, fontsize = 14, cluster_rows = F, cluster_cols = F, scale = "row",
           color = colorRampPalette(rev(brewer.pal(n = 7, name = "RdYlBu")))(100))
}

plot_heatmap_r2(rf_result_17feat)

# Make the full model baseline for R2
rf_result_18feat = data.frame(apply(rf_result[1:7, 1:10], 1, mean))
rf_result_18feat = data.frame(rep(rf_result_18feat, 18))
rownames(rf_result_18feat) = ephys_interest
colnames(rf_result_18feat) = 1:18



## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column    
  datac <- rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}

fit_list$id = sub("^0", "", (gsub("[^0-9]+", "", row.names(fit_list))))
fit_list$id[1:20] = 0
fit_list$var = row.names(fit_list)
fit_list$var = sub("\\d*$", "\\1", fit_list$var)

fit_res <- dcast(data = fit_list, formula = id ~ var, value.var = "%IncMSE")
fit_res$id <- NULL
fs_res <- fs_list
colnames(fs_res) <- colnames(fit_res)
fs_res$Y = ephys_interest
fit_res$Y = ephys_interest


# Plot feature selection results
# Out-of-the-box RF importance mean-decrease-accuracy measure
# Chernoff faces
library(tcltk)
library(aplpack)

plot_fs <- function(dat, title) {
  pd <- position_jitter(width = 0.3, height = 0)
  plot_data <- melt(dat, id=c("Y"))
  plot_data$value <- log10(plot_data$value)
  plot_data_se <- summarySE(plot_data, measurevar = "value", groupvars = c("variable", "Y"))
  print(ggplot(plot_data_se, aes(x = variable, y = value, colour = Y)) +
    geom_pointrange(aes(ymin = value - se, ymax = value + se, colour = Y), width=.3, size = 1, position = pd) +
    scale_colour_brewer(palette = "Dark2") +
    ggtitle(title) +
    expand_limits(y = 0) +
    labs(x = "Metadata", y = "log10(Mean Decrease Accuracy)") +
    theme_grey(15) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)))
  
  dat_se <- aggregate(fs_res[,1:20], list(Y = fit_res$Y), mean)
  faces(dat_se[,2:21], face.type = 1, labels = dat_se$Y)
}

plot_fs(fit_res, "RF feature importance (normal)")
plot_fs(fs_res, "RF feature importance (cforest)")

# Plot relative impact of each metadata on ephys.
plot_heatmap_fs <- function(dat, title) {
  plot_data <- aggregate(dat[, 1:length(features)], list(Y = dat$Y), mean)
  row.names(plot_data) <- plot_data$Y
  plot_data$Y <- NULL
  
  pheatmap(plot_data, show_colnames = T, fontsize = 14, cluster_rows = F, cluster_cols = F, scale = "none",
         color = colorRampPalette(rev(brewer.pal(n = 7, name = "YlOrRd")))(100))
}

plot_heatmap_fs(fit_res, "RF feature importance per ephys. prop (normal)")
plot_heatmap_fs(fs_res, "RF feature importance per ephys. prop (cforest)")

seq <- sub("_err|_n", "\\1", colnames(q))

plot_data <- melt(fit_result)
# Plot the resulting R^2 values
ggplot(plot_data, aes(x = variable, y = value)) + geom_boxplot(aes(fill = variable)) +
  ggtitle("No solutions - 8 vars") +
  ylim(-1, 1) + 
  labs(x = "Ephys. props.", y = "R^2 values") +
  theme_bw(15)
rm(plot_data)

# RF error increase based on feature removal
xval <- rfcv(data_models_x, data_models[,"rmp"], cv.fold = 10, recursive = T)
with(xval, plot(n.var, error.cv))
rm(xval)

ggplot(subset(data_models, log10(AnimalAge) > 1 & log10(AnimalAge) < 2), aes(x = log10(AnimalAge), y = tau)) + geom_point(size = 2) + stat_smooth(method = "lm") + theme_bw(15)
ggplot(subset(data_models, log10(AnimalAge) > 1 & log10(AnimalAge) < 2 & tau > 0.1 & tau < 2), aes(x = log10(AnimalAge), y = tau)) + geom_point(size = 2) + stat_smooth(method = "lm") + theme_bw(15)

ggplot(subset(data_models, apamp > 0), aes(x = JxnPotential, y = apamp)) + geom_point(size = 2) + stat_smooth(method = "lm") + theme_bw(15)

ggplot(data_models, aes(x = NeuronName, y = rmp)) + geom_point(size = 2) + stat_smooth(method = "lm") + theme_bw(15)

ggplot(data_models, aes(x = as.factor(PubYear), y = rmp)) + geom_boxplot(size = 2) + labs(x = "Year published", y = "resting membrane potential") + theme_bw(15)
ggplot(subset(data_models, NeuronName == "Hippocampus CA1 pyramidal cell"), aes(x = as.factor(PubYear), y = rmp)) + geom_boxplot(size = 2) + labs(x = "Year published", y = "resting membrane potential") + theme_bw(15)

### Feature correlation testing
plot_data <- as.data.frame(cor(fit_data[, features], use = "pairwise", method = "spearman"))
for (i in 1:ncol(plot_data)) {
  plot_data[i,i] <- NA
}
pheatmap(plot_data, show_colnames = T, fontsize = 14, cluster_rows = F, cluster_cols = F, scale = "none",
         color = colorRampPalette(rev(brewer.pal(n = 7, name = "YlOrRd")))(100))

g <- ggbiplot(prcomp(fit_data[,features], scale = T), obs.scale = 1, var.scale = 1)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
g <- g + xlim(-2,4) + ylim(-3, 2.5)
print(g)

for (i in 1:length(no_solns)) {
  print(summary(lm(as.formula(paste0(no_solns[i], " ~ ", paste(solns, collapse = "+"))), fit_data)))
}

# Try neural net

#mod <- neuralnet(AND + OR ~ Var1 + Var2 + Var3, binary_data,
#                 hidden = c(6, 12, 8), rep = 10, err.fct = 'ce', linear.output = FALSE)

nn <- neuralnet(as.formula(paste0(paste(features, collapse = "+"), " ~ ", paste(solns, collapse = "+"))), fit_data, hidden = c(12, 24, 10), rep = 10, err.fct = 'sse', linear.output = FALSE)

par(mar = numeric(4), family = 'serif')
plotnet(nn, alpha = 0.6)

### Compare variances within articles to between articles
plot_sd <- function(dat) {
  i = 1
  plots = list()
  for (ep in ephys_interest) {
    plot_data = na.omit(as.data.frame(dat[, paste0(ep, "_sd")]))
    colnames(plot_data) = c("value")
    plot_data$model = "within article"
    temp = dat[, c(ep, paste0(ep, "_sd"))]
    temp = temp[complete.cases(temp),]
    toAdd = data.frame(sd(temp[, ep], na.rm = T), model = "between articles")
    colnames(toAdd) = c("value", "model")
    plot_data = rbind(plot_data, toAdd)
    
    # geom_point(position = "jitter") + geom_hline(yintercept = median(plot_data$value))
    g = ggplot(plot_data, aes(x = model, y = value)) + geom_boxplot(aes(fill = model)) + ggtitle(paste0("SD comparison for EP: ", ep)) + theme_bw(15)
    plots[[i]] = g
    i = i + 1
  }
  print(multiplot(plotlist = plots, cols = 3))
}

plot_sd(weighted_data_models)

### R2 vs number of data lines
plot_data = as.data.frame(apply(rf_result[[6]][1:7,], 1, mean))
plot_data$ep = row.names(plot_data)
colnames(plot_data) = c("r2", "ep")
plot_data$n = 0
for (i in 1:length(ephys_interest)) {
  ep = ephys_interest[i]
  run_data = weighted_fit_data[!is.na(weighted_fit_data[,ep]),]
  run_data = run_data[complete.cases(run_data[,c(ep, features, paste0(ep, "_freq"))]),]
  plot_data[i, "n"] = nrow(run_data)
}
rm(run_data, i)

fit = lm(as.formula("r2 ~ n"), plot_data)
ggplot(plot_data, aes(x = n, y = r2)) + geom_point() + stat_smooth(method = "lm", col = "red") + labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
                                                                                                                    "Intercept =",signif(fit$coef[[1]],5 ),
                                                                                                                    " Slope =",signif(fit$coef[[2]], 5),
                                                                                                                    " P =",signif(summary(fit)$coef[2,4], 5))) + theme_bw(15)
rm(fit, plot_data)

### Z-test for likelihood of 1 article's mean to be similar to another (same neuron type)
# Z = (mean_1 - mean_2) / sqrt(SEM_1^2 + SEM_2^2)
z_data = subset(data_models, NeuronName == "Hippocampus CA1 pyramidal cell")
rownames(z_data) = 1:nrow(z_data)
z_data = subset(z_data, !is.na(rmp))

ggplot(z_data, aes(x = rmp_sd)) +
  geom_density(alpha = 0.1, fill = "orange") +
  #scale_x_continuous(breaks = pretty_breaks(n = 10)) + 
  labs(x = "Standard deviation", y = "Article count") +
  geom_vline(xintercept = sd(z_data$rmp)) +
  theme_bw(15)

ggplot(data_models, aes(x = rmp, y = rmp_sd)) + 
  geom_point() +
  theme_bw(15)

# Try 1 z-score calculation
abs(z_data[20, "rmp"] - z_data[22, "rmp"]) / sqrt(z_data[20, "rmp_err"]^2 + z_data[22, "rmp_err"]^2)

library(HH)
anova_data = subset(z_data, !duplicated(Pmid))
anova_data = subset(anova_data, !is.na(rmp_sd))
anova_data$Pmid = as.factor(anova_data$Pmid)
anova_data$n = anova_data$rmp_n
anova_data$s = anova_data$rmp_sd
summary(aovSufficient(rmp ~ Pmid, data = anova_data))

z_result = combn(rownames(z_data), 2, FUN = function (i) {
  z = (z_data[i[[1]], "rmp"] - z_data[i[[2]], "rmp"]) / sqrt(z_data[i[[1]], "rmp_err"]^2 + z_data[i[[2]], "rmp_err"]^2)
})
p_result = unlist(lapply(z_result, function(x) {2*pnorm(-abs(x))}))
summary(p_result)

# For each pair of articles - calculate z-score (and p-value of them being from the same distribution). Do that for each ep of interest.
test = data.frame(NeuronName = character(0), Z = numeric(0))
test$NeuronName = unique(data_models$NeuronName)
for (i in unique(data_models$NeuronName)) {
  
}

# Can check RMP ~ pmid (also use n, standard dev / error, mean) <- later

# Check articles from the same author (or lab) - how do their results compare across experiments? Ryan / Nathalie project
table(data_models$LastAuthor)
test = subset(data_models, NeuronName == "Hippocampus CA1 pyramidal cell")
table(test$LastAuthor)
test_1 = subset(test, LastAuthor == "Disterhoft JF")

source("CVfunc.R")
temp = runCV(df = fit_data, model = cv.glmnet, formula = "rmp ~ NeuronName", model_args = list( "nlambda" = 100, "alpha"=.99, "na.action" = na.omit), predict_args = list("s" = "lambda.min"), splitNN = T, unique = T)

# Try predicting Rin with less N – does R2 decrease proportionally?

# Compare within and between lab variability for labs with at least 3 papers